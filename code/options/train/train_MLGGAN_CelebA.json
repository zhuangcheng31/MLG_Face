{
    "name": "GAN_SFT_CelebA_0401",
    "_comment": "68 face landmarks, connect HG over steps by feature average between each stacks",
    "mode": "sr_align_gan",
    "gpu_ids": [0,1],  //[0,1]
    "use_tb_logger": true,
    "scale": 8,
    "is_train": true,
    "rgb_range": 1,
    "save_image": true,
    "datasets": {
        "train": {
            "mode": "HRLandmark",
            "name": "CelebALandmarkTrain",
            "dataroot_HR": "/opt/data/private/img_celeba_all",//"/home/jzy/datasets/SR_datasets/CelebA/img_celeba",
            "info_path":  "/root/tmp/mlg_face/annotations/CelebA_train.pkl",
            "data_type": "img",
            "n_workers": 8,
            "batch_size":8, //8,
            "LR_size": 16,
            "HR_size": 128,
            "use_flip": false,
            "use_rot": false,
            "sigma": 1
        },
        "val": {
            "mode": "HRLandmark",
            "name": "CelebALandmarkVal",
            "dataroot_HR":"/opt/data/private/img_celeba_all", //"/home/jzy/datasets/SR_datasets/CelebA/img_celeba",
            "info_path": "/root/tmp/mlg_face/annotations/CelebA_val.pkl",   //"/home/jzy/datasets/SR_datasets/CelebA/new_val_info_list.pkl",
            "data_type": "img",
            "LR_size": 16,
            "HR_size": 128,
            "sigma": 1
        }
    },
    "networks": {
        "which_model": "MLG",  //"MLGGAN",
        "num_features": 48,
        "in_channels": 3,
        "out_channels": 3,
        "num_steps": 4,
        "num_groups": 6,
        "detach_attention":  true , //false,
        "hg_num_feature": 256,
        "hg_num_keypoints": 68,
        "num_fusion_block": 7
    },
    "net_D": {
       "which_model_D": "LightCNN"
    },
    "net_F": {
      "which_model_F": "LightCNN"
    },
    "solver": {
        "type": "ADAM",
        "learning_rate_G": 0.0001,
        "weight_decay_G": 0,
        "learning_rate_D": 0.0001,
        "weight_decay_D": 0,
        "lr_scheme": "MultiStepLR",
        "lr_steps": [
            1e4, 2e4, 4e4
        ],
        "lr_gamma": 0.5,
        "manual_seed": 0,
        "save_freq":4e3, //2e3,
        "val_freq":2e3,  //1e3,
        "niter": 8e5, //8e4,
        "num_save_image": 10,  //20,
        "log_full_step": true,
        "pretrain":true, //true,
        "extractor_pretrained_path": "../models/LightCNN_feature.pth",
        "generator_pretrained_path": "/opt/data/private/FSR/mlg_face/experiments/MLG_in3f48_x8_MLG_CelebA_SFT_0401/epochs/step_0060000_ckp.pth",
        //"../experiments/MLG_in3f48_x8_MLGGAN_CelebA/epochs/best_ckp.pth", //"../experiments/MLG_in3f48_x8_MLG_CelebA/epochs/best_ckp.pth",
        "release_HG_grad_step": 2e3,
        "loss": {
            "pixel": {
                "loss_type": "l1",
                "weight": 1
            },
            "align": {
                "loss_type": "l2", // "AdapWingLoss", //"l2",
                "weight": 1e-1
            },
            "feature": {
              "loss_type": "l1",
              "weight": 0.1
            },
            "GAN": {
              "loss_type": "GAN",
              "gan_type": "vanilla",
              "weight": 0.005
            }
        }
    },
    "logger": {
        "print_freq": 250
    },
    "path": {
      "root": "../"
    }
}

