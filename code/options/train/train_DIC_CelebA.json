
{
    "name": "DIC_CelebA_SFT_0410",
    "mode": "sr_align",
    "gpu_ids": [0, 1],
    "use_tb_logger": true,
    "scale": 8,
    "is_train": true,
    "rgb_range": 1,
    "save_image": true,
    "datasets": {
        "train": {
            "mode": "HRLandmark",
            "name": "CelebALandmarkTrain",
            "dataroot_HR": "/opt/data/private/img_celeba_all",
            "info_path": "/root/tmp/mlg_face/annotations/CelebA_train.pkl",
            "data_type": "img",
            "n_workers": 8,
            "batch_size": 8,
            "LR_size": 16,
            "HR_size": 128,
            "use_flip": false,
            "use_rot": false,
            "sigma": 1
        },
        "val": {
            "mode": "HRLandmark",
            "name": "CelebALandmarkVal",
            "dataroot_HR": "/opt/data/private/img_celeba_all",
            "info_path": "/root/tmp/mlg_face/annotations/CelebA_val.pkl",
            "data_type": "img",
            "LR_size": 16,
            "HR_size": 128,
            "sigma": 1
        }
    },
    "networks": {
        "which_model": "MLG",
        "num_features": 48,
        "in_channels": 3,
        "out_channels": 3,
        "num_steps": 4,
        "num_groups": 6,
        "detach_attention": false,
        "hg_num_feature": 256,
        "hg_num_keypoints": 68,
        "num_fusion_block": 7
    },
    "solver": {
        "type": "ADAM",
        "learning_rate": 1e-4,
        "weight_decay": 0,
        "lr_scheme": "MultiStepLR",
        "lr_steps": [
            1e4, 2e4, 4e4, 8e4
        ],
        "lr_gamma": 0.5,
        "manual_seed": 0,
        "save_freq": 4e3, //5e3,
        "val_freq": 2e3, //2e3,
        "niter": 1.5e5,  //1.5e5
        "num_save_image": 10,
        "log_full_step": true,
        "pretrain":true, //false,
        "pretrained_path": "/opt/data/private/FSR/mlg_face/experiments/DIC_in3f48_x8_debug_Helen_useColla_0331/epochs/step_0060000_ckp.pth",//"/root/tmp/mlg_face/models/DIC_CelebA.pth", //chengjia
        "release_HG_grad_step": 2e3,
        "HG_pretrained_path": "/root/tmp/mlg_face/models/FB_HG_68_CelebA.pth",
        "loss": {
            "pixel": {
                "loss_type": "l1",
                "weight": 1
            },
            "align": {
                "loss_type":"AdapWingLoss",  //"l2"
                "weight": 1e-1    //1e-1       0.25 0.0551
            }
        }
    },
    "logger": {
        "print_freq": 250
    },
    "path": {
      "root": "../"
    }
}

